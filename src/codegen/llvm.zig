const std = @import("std");
const mem = std.mem;

const mir = @import("mir.zig");
const MIRModule = mir.MIRModule;
const MIRFunction = mir.MIRFunction;
const MInst = mir.MInst;
const VReg = mir.VReg;
const Width = mir.Width;
const BinOp = mir.BinOp;
const CmpOp = mir.CmpOp;
const GlobalVars = mir.GlobalVars;

const codegen = @import("codegen.zig");
const Target = codegen.Target;

const CallingConvention = @import("../parser/ast.zig").CallingConvention;
const TypeRegistry = @import("../semantic/types.zig").TypeRegistry;
const TypeId = @import("../semantic/types.zig").TypeId;

/// Lower MIR module to LLVM IR text format.
pub fn lower(allocator: mem.Allocator, module: *const MIRModule, types: *const TypeRegistry, target: Target) ![]const u8 {
    var emitter = try Emitter.init(allocator, target);
    defer emitter.deinit();

    // module header
    try emitter.comment("Generated by the Honey compiler");
    try emitter.raw("source_filename = \"honey\"");
    try emitter.appendFmt("target triple = \"{s}\"\n", .{target.getLLVMTriple()});
    try emitter.newline();

    // emit struct type definitions
    try emitStructTypes(&emitter, types);

    // emit memcpy intrinsic if any struct types have struct fields
    if (needsMemcpy(types)) {
        try emitter.raw("declare void @llvm.memcpy.p0.p0.i64(ptr, ptr, i64, i1)");
        try emitter.newline();
    }

    // emit global variable declarations
    try emitGlobals(&emitter, &module.globals, types);

    // emit extern function declarations
    for (module.extern_functions.items) |ext| {
        try emitExternDecl(&emitter, &ext);
    }
    if (module.extern_functions.items.len > 0) {
        try emitter.newline();
    }

    // emit function definitions
    var has_main = false;
    for (module.functions.items) |*func| {
        if (std.mem.eql(u8, func.name, "main")) has_main = true;
        try lowerFunction(&emitter, func, &module.globals, types);
    }

    // emit trap stub if no main function was defined
    if (!has_main) {
        try emitter.raw("declare void @llvm.trap() noreturn nounwind");
        try emitter.newline();
        try emitter.raw("define i32 @main() {");
        try emitter.raw("entry:");
        try emitter.raw("  call void @llvm.trap()");
        try emitter.raw("  unreachable");
        try emitter.raw("}");
        try emitter.newline();
    }

    // register __honey_init as a global constructor so it runs before main
    try emitter.raw("@llvm.global_ctors = appending global [1 x { i32, ptr, ptr }] [{ i32, ptr, ptr } { i32 65535, ptr @__honey_init, ptr null }]");
    try emitter.newline();

    return try allocator.dupe(u8, emitter.getOutput());
}

fn emitStructTypes(emitter: *Emitter, types: *const TypeRegistry) !void {
    for (types.struct_types.items) |st| {
        try emitter.appendFmt("%{s} = type {{ ", .{st.name});
        for (st.fields, 0..) |field, i| {
            if (i > 0) try emitter.appendSlice(", ");
            if (field.type_id.isStruct()) {
                const inner = types.struct_types.items[field.type_id.struct_type];
                try emitter.appendFmt("%{s}", .{inner.name});
            } else {
                try emitter.appendSlice(typeIdToLLVMType(field.type_id));
            }
        }
        try emitter.appendSlice(" }\n");
    }
    if (types.struct_types.items.len > 0) {
        try emitter.newline();
    }
}

fn needsMemcpy(types: *const TypeRegistry) bool {
    return types.struct_types.items.len > 0;
}

fn emitGlobals(emitter: *Emitter, globals: *const GlobalVars, types: *const TypeRegistry) !void {
    for (0..globals.count()) |i| {
        const idx: mir.GlobalIndex = @intCast(i);
        const name = globals.getName(idx);
        const type_id = globals.getTypeId(idx);
        const is_const = globals.getIsConst(idx);
        const linkage = if (is_const) "constant" else "global";

        if (type_id.isStruct()) {
            const struct_type = types.struct_types.items[type_id.struct_type];
            if (globals.getStructInit(idx)) |field_values| {
                // Static initializer: @P = constant/global %Point { i32 42, i32 54 }
                try emitter.appendFmt("@{s} = {s} %{s} {{ ", .{ name, linkage, struct_type.name });
                for (struct_type.fields, 0..) |field, fi| {
                    if (fi > 0) try emitter.appendSlice(", ");
                    const field_llvm = typeIdToLLVMType(field.type_id);
                    if (isFloatType(field.type_id)) {
                        // Emit IEEE 754 double-precision hex (LLVM format for float constants)
                        const bits: u64 = @bitCast(field_values[fi]);
                        try emitter.appendFmt("{s} 0x{X:0>16}", .{ field_llvm, bits });
                    } else {
                        try emitter.appendFmt("{s} {d}", .{ field_llvm, field_values[fi] });
                    }
                }
                try emitter.appendSlice(" }\n");
            } else {
                // Runtime-initialized struct
                try emitter.appendFmt("@{s} = {s} %{s} zeroinitializer\n", .{ name, linkage, struct_type.name });
            }
        } else {
            const width = globals.getWidth(idx);
            const type_str = widthToLLVMType(width);
            const init_value = globals.getInitValue(idx);

            if (init_value) |val| {
                if (width.isFloat()) {
                    const bits: u64 = @bitCast(val);
                    try emitter.appendFmt("@{s} = {s} {s} 0x{X:0>16}\n", .{ name, linkage, type_str, bits });
                } else {
                    try emitter.appendFmt("@{s} = {s} {s} {d}\n", .{ name, linkage, type_str, val });
                }
            } else {
                if (width.isFloat()) {
                    try emitter.appendFmt("@{s} = {s} {s} 0.0\n", .{ name, linkage, type_str });
                } else {
                    try emitter.appendFmt("@{s} = {s} {s} 0\n", .{ name, linkage, type_str });
                }
            }
        }
    }
    if (globals.count() > 0) {
        try emitter.newline();
    }
}

fn emitExternDecl(emitter: *Emitter, ext: *const mir.ExternFunc) !void {
    const cc_attr = ccAttr(ext.call_conv);
    const ret_str = if (ext.return_width) |w| widthToLLVMType(w) else "void";

    try emitter.appendFmt("declare {s}{s} @{s}(", .{ cc_attr, ret_str, ext.name });

    for (ext.param_widths, 0..) |pw, j| {
        if (j > 0) try emitter.appendSlice(", ");
        try emitter.appendSlice(widthToLLVMType(pw));
    }

    try emitter.appendSlice(")\n");
}

fn lowerFunction(emitter: *Emitter, func: *const MIRFunction, globals: *const GlobalVars, types: *const TypeRegistry) !void {
    const cc_attr = ccAttr(func.call_conv);

    if (func.sret_struct_idx) |struct_idx| {
        // sret function: returns void, first param is hidden sret pointer
        const struct_type = types.struct_types.items[struct_idx];
        try emitter.appendFmt("define {s}void @{s}(ptr sret(%{s}) %arg0", .{
            cc_attr, func.name, struct_type.name,
        });
        // remaining params shifted by 1
        for (func.params, 0..) |param, i| {
            try emitter.appendFmt(", {s} %arg{d}", .{ widthToLLVMType(param.width), i + 1 });
        }
        try emitter.appendSlice(") {\n");
    } else {
        const ret_str = if (func.return_width) |w| widthToLLVMType(w) else "void";

        // function signature with parameters
        try emitter.appendFmt("define {s}{s} @{s}(", .{ cc_attr, ret_str, func.name });

        for (func.params, 0..) |param, i| {
            if (i > 0) try emitter.appendSlice(", ");
            try emitter.appendFmt("{s} %arg{d}", .{ widthToLLVMType(param.width), i });
        }

        try emitter.appendSlice(") {\n");
    }
    try emitter.raw("entry:");

    // track SSA values: vreg -> LLVM SSA name
    var ssa_map = SsaMap{};

    // track alloca pointers keyed by fp-offset (from store_arg/store_local/load_local)
    var alloca_map = AllocaMap{};

    for (func.instructions.items) |inst| {
        try lowerInst(emitter, inst, &ssa_map, &alloca_map, func, globals, types);
    }

    // If the last instruction is not a terminator, add an implicit return
    // to keep LLVM happy (e.g. a label at the end with no further code).
    const last = func.instructions.items[func.instructions.items.len - 1];
    const needs_ret = switch (last) {
        .ret, .br, .br_cond => false,
        else => true,
    };
    if (needs_ret) {
        if (func.return_width) |w| {
            const zero_str: []const u8 = if (w.isFloat()) "0.0" else "0";
            try emitter.appendFmt("  ret {s} {s}\n", .{ widthToLLVMType(w), zero_str });
        } else {
            try emitter.appendSlice("  ret void\n");
        }
    }

    try emitter.raw("}");
    try emitter.newline();
}

fn lowerInst(
    emitter: *Emitter,
    inst: MInst,
    ssa_map: *SsaMap,
    alloca_map: *AllocaMap,
    func: *const MIRFunction,
    globals: *const GlobalVars,
    types: *const TypeRegistry,
) !void {
    switch (inst) {
        .mov_imm => |op| {
            const ssa_name = ssa_map.allocFor(op.dst);
            const type_str = widthToLLVMType(op.width);
            if (op.width.isFloat()) {
                // Float immediate: value holds IEEE 754 bits, emit as LLVM hex float
                const bits: u64 = @bitCast(op.value);
                try emitter.appendFmt("  %{d} = fadd {s} 0.0, 0x{X:0>16}\n", .{ ssa_name, type_str, bits });
            } else {
                try emitter.appendFmt("  %{d} = add {s} 0, {d}\n", .{ ssa_name, type_str, op.value });
            }
        },

        .mov_reg => |op| {
            const src_ssa = ssa_map.get(op.src);
            const dst_ssa = ssa_map.allocFor(op.dst);
            const type_str = widthToLLVMType(op.width);
            if (op.width.isFloat()) {
                try emitter.appendFmt("  %{d} = fadd {s} %{d}, 0.0\n", .{ dst_ssa, type_str, src_ssa });
            } else {
                try emitter.appendFmt("  %{d} = add {s} %{d}, 0\n", .{ dst_ssa, type_str, src_ssa });
            }
        },

        .binop => |op| {
            const lhs_ssa = ssa_map.get(op.lhs);
            const rhs_ssa = ssa_map.get(op.rhs);
            const dst_ssa = ssa_map.allocFor(op.dst);
            const type_str = widthToLLVMType(op.width);
            const op_str = if (op.width.isFloat()) floatBinOpToLLVM(op.op) else binOpToLLVM(op.op);

            try emitter.appendFmt("  %{d} = {s} {s} %{d}, %{d}\n", .{
                dst_ssa, op_str, type_str, lhs_ssa, rhs_ssa,
            });
        },

        .cmp => |op| {
            const lhs_ssa = ssa_map.get(op.lhs);
            const rhs_ssa = ssa_map.get(op.rhs);
            const dst_ssa = ssa_map.allocFor(op.dst);
            const type_str = widthToLLVMType(op.width);

            if (op.width.isFloat()) {
                const fcmp_op_str = floatCmpOpToLLVM(op.op);
                // fcmp returns i1, zero-extend to i8 (bool)
                try emitter.appendFmt("  %cmp{d} = fcmp {s} {s} %{d}, %{d}\n", .{
                    dst_ssa, fcmp_op_str, type_str, lhs_ssa, rhs_ssa,
                });
                try emitter.appendFmt("  %{d} = zext i1 %cmp{d} to i8\n", .{
                    dst_ssa, dst_ssa,
                });
            } else {
                const cmp_op_str = cmpOpToLLVM(op.op);
                // icmp returns i1, zero-extend to i8 (bool)
                try emitter.appendFmt("  %cmp{d} = icmp {s} {s} %{d}, %{d}\n", .{
                    dst_ssa, cmp_op_str, type_str, lhs_ssa, rhs_ssa,
                });
                try emitter.appendFmt("  %{d} = zext i1 %cmp{d} to i8\n", .{
                    dst_ssa, dst_ssa,
                });
            }
        },

        .ret => |op| {
            if (op.value) |vreg| {
                const src_ssa = ssa_map.get(vreg);
                const ret_type = if (func.return_width) |w| widthToLLVMType(w) else "i32";
                try emitter.appendFmt("  ret {s} %{d}\n", .{ ret_type, src_ssa });
            } else {
                if (func.return_width) |w| {
                    // non-void function with no explicit value — return 0
                    const zero_str: []const u8 = if (w.isFloat()) "0.0" else "0";
                    try emitter.appendFmt("  ret {s} {s}\n", .{ widthToLLVMType(w), zero_str });
                } else {
                    try emitter.appendSlice("  ret void\n");
                }
            }
        },

        .prologue, .epilogue => {
            // LLVM handles prologue/epilogue automatically
        },

        .store_arg => |op| {
            const type_str = widthToLLVMType(op.width);
            // allocate a stack slot for this parameter
            const alloca_id = alloca_map.getOrCreate(op.offset);
            try emitter.appendFmt("  %local.{d} = alloca {s}\n", .{ alloca_id, type_str });
            try emitter.appendFmt("  store {s} %arg{d}, ptr %local.{d}\n", .{ type_str, op.arg_idx, alloca_id });
        },

        .store_local => |op| {
            const src_ssa = ssa_map.get(op.src);
            const type_str = widthToLLVMType(op.width);
            const alloca_id = alloca_map.getOrCreate(op.offset);

            // emit alloca on first use of this offset
            if (!alloca_map.isEmitted(op.offset)) {
                try emitter.appendFmt("  %local.{d} = alloca {s}\n", .{ alloca_id, type_str });
                alloca_map.markEmitted(op.offset);
            }

            try emitter.appendFmt("  store {s} %{d}, ptr %local.{d}\n", .{ type_str, src_ssa, alloca_id });
        },

        .load_local => |op| {
            const dst_ssa = ssa_map.allocFor(op.dst);
            const type_str = widthToLLVMType(op.width);
            const alloca_id = alloca_map.getOrCreate(op.offset);

            try emitter.appendFmt("  %{d} = load {s}, ptr %local.{d}\n", .{ dst_ssa, type_str, alloca_id });
        },

        .store_global => |op| {
            const src_ssa = ssa_map.get(op.src);
            const type_str = widthToLLVMType(op.width);
            const name = globals.getName(op.global_idx);

            try emitter.appendFmt("  store {s} %{d}, ptr @{s}\n", .{ type_str, src_ssa, name });
        },

        .load_global => |op| {
            const dst_ssa = ssa_map.allocFor(op.dst);
            const type_str = widthToLLVMType(op.width);
            const name = globals.getName(op.global_idx);

            try emitter.appendFmt("  %{d} = load {s}, ptr @{s}\n", .{ dst_ssa, type_str, name });
        },

        .label => |id| {
            try emitter.appendFmt("lbl.{d}:\n", .{id});
        },

        .br_cond => |op| {
            const cond_ssa = ssa_map.get(op.cond);
            const cond_type = widthToLLVMType(op.cond_width);
            // convert condition to i1 for LLVM br
            const cmp_id = ssa_map.next_ssa;
            ssa_map.next_ssa += 1;
            try emitter.appendFmt("  %cond.{d} = icmp ne {s} %{d}, 0\n", .{ cmp_id, cond_type, cond_ssa });
            try emitter.appendFmt("  br i1 %cond.{d}, label %lbl.{d}, label %lbl.{d}\n", .{
                cmp_id, op.true_label, op.false_label,
            });
        },

        .br => |target| {
            try emitter.appendFmt("  br label %lbl.{d}\n", .{target});
        },

        .call => |op| {
            std.debug.assert(op.args.len == op.arg_widths.len);
            const call_cc = ccAttr(op.call_conv);

            if (op.sret_struct_idx) |struct_idx| {
                // sret call: first arg gets sret attribute, call returns void
                const struct_type = types.struct_types.items[struct_idx];
                var args_str = try std.ArrayList(u8).initCapacity(emitter.allocator, 128);
                defer args_str.deinit(emitter.allocator);

                // first arg: sret pointer
                const first_ssa = ssa_map.get(op.args[0]);
                var buf: [64]u8 = undefined;
                const sret_fmt = std.fmt.bufPrint(&buf, "ptr sret(%{s}) %{d}", .{
                    struct_type.name, first_ssa,
                }) catch unreachable;
                try args_str.appendSlice(emitter.allocator, sret_fmt);

                // remaining args
                for (op.args[1..], op.arg_widths[1..]) |arg_vreg, arg_width| {
                    try args_str.appendSlice(emitter.allocator, ", ");
                    const arg_ssa = ssa_map.get(arg_vreg);
                    const arg_type = widthToLLVMType(arg_width);
                    var abuf: [32]u8 = undefined;
                    const arg_fmt = std.fmt.bufPrint(&abuf, "{s} %{d}", .{ arg_type, arg_ssa }) catch unreachable;
                    try args_str.appendSlice(emitter.allocator, arg_fmt);
                }

                try emitter.appendFmt("  call {s}void @{s}({s})\n", .{
                    call_cc, op.func_name, args_str.items,
                });
            } else {
                // normal call
                var args_str = try std.ArrayList(u8).initCapacity(emitter.allocator, 64);
                defer args_str.deinit(emitter.allocator);

                for (op.args, op.arg_widths, 0..) |arg_vreg, arg_width, i| {
                    if (i > 0) try args_str.appendSlice(emitter.allocator, ", ");
                    const arg_ssa = ssa_map.get(arg_vreg);
                    const arg_type = widthToLLVMType(arg_width);
                    var buf: [32]u8 = undefined;
                    const arg_fmt = std.fmt.bufPrint(&buf, "{s} %{d}", .{ arg_type, arg_ssa }) catch unreachable;
                    try args_str.appendSlice(emitter.allocator, arg_fmt);
                }

                if (op.dst) |dst_vreg| {
                    const dst_ssa = ssa_map.allocFor(dst_vreg);
                    const ret_type = widthToLLVMType(op.width);
                    try emitter.appendFmt("  %{d} = call {s}{s} @{s}({s})\n", .{
                        dst_ssa, call_cc, ret_type, op.func_name, args_str.items,
                    });
                } else {
                    try emitter.appendFmt("  call {s}void @{s}({s})\n", .{
                        call_cc, op.func_name, args_str.items,
                    });
                }
            }
        },

        .load_field => |op| {
            const base_ssa = ssa_map.get(op.base);
            const struct_type = types.struct_types.items[op.struct_idx];
            const field_type_id = struct_type.fields[op.field_idx].type_id;

            if (field_type_id.isStruct()) {
                // struct field: GEP only — the pointer to the embedded struct IS the value
                const dst_ssa = ssa_map.allocFor(op.dst);
                try emitter.appendFmt("  %{d} = getelementptr inbounds %{s}, ptr %{d}, i32 0, i32 {d}\n", .{
                    dst_ssa, struct_type.name, base_ssa, op.field_idx,
                });
            } else {
                // primitive field: GEP + load
                const gep_ssa = ssa_map.next_ssa;
                ssa_map.next_ssa += 1;
                try emitter.appendFmt("  %gep.{d} = getelementptr inbounds %{s}, ptr %{d}, i32 0, i32 {d}\n", .{
                    gep_ssa, struct_type.name, base_ssa, op.field_idx,
                });

                const dst_ssa = ssa_map.allocFor(op.dst);
                try emitter.appendFmt("  %{d} = load {s}, ptr %gep.{d}\n", .{
                    dst_ssa, widthToLLVMType(op.width), gep_ssa,
                });
            }
        },

        .alloca_struct => |op| {
            const struct_type = types.struct_types.items[op.struct_idx];
            const dst_ssa = ssa_map.allocFor(op.dst);
            try emitter.appendFmt("  %{d} = alloca %{s}\n", .{ dst_ssa, struct_type.name });
        },

        .store_field => |op| {
            const base_ssa = ssa_map.get(op.base);
            const value_ssa = ssa_map.get(op.value);
            const struct_type = types.struct_types.items[op.struct_idx];
            const field_type_id = struct_type.fields[op.field_idx].type_id;

            // emit GEP to get pointer to field
            const gep_ssa = ssa_map.next_ssa;
            ssa_map.next_ssa += 1;
            try emitter.appendFmt("  %gep.{d} = getelementptr inbounds %{s}, ptr %{d}, i32 0, i32 {d}\n", .{
                gep_ssa, struct_type.name, base_ssa, op.field_idx,
            });

            if (field_type_id.isStruct()) {
                // struct field: memcpy the inline data
                const inner = types.struct_types.items[field_type_id.struct_type];
                try emitter.appendFmt("  call void @llvm.memcpy.p0.p0.i64(ptr %gep.{d}, ptr %{d}, i64 {d}, i1 false)\n", .{
                    gep_ssa, value_ssa, inner.size,
                });
            } else {
                // primitive field: direct store
                try emitter.appendFmt("  store {s} %{d}, ptr %gep.{d}\n", .{
                    widthToLLVMType(op.width), value_ssa, gep_ssa,
                });
            }
        },
        .copy_struct => |op| {
            const dst_ssa = ssa_map.get(op.dst);
            const src_ssa = ssa_map.get(op.src);
            const struct_type = types.struct_types.items[op.struct_idx];
            try emitter.appendFmt("  call void @llvm.memcpy.p0.p0.i64(ptr %{d}, ptr %{d}, i64 {d}, i1 false)\n", .{
                dst_ssa, src_ssa, struct_type.size,
            });
        },

        .addr_of_local => |op| {
            const dst_ssa = ssa_map.allocFor(op.dst);
            const alloca_id = alloca_map.getOrCreate(op.offset);
            try emitter.appendFmt("  %{d} = getelementptr i8, ptr %local.{d}, i32 0\n", .{ dst_ssa, alloca_id });
        },

        .addr_of_global => |op| {
            const dst_ssa = ssa_map.allocFor(op.dst);
            const name = globals.getName(op.global_idx);
            try emitter.appendFmt("  %{d} = getelementptr i8, ptr @{s}, i32 0\n", .{ dst_ssa, name });
        },

        .load_ptr => |op| {
            const ptr_ssa = ssa_map.get(op.ptr);
            const dst_ssa = ssa_map.allocFor(op.dst);
            const type_str = widthToLLVMType(op.width);
            try emitter.appendFmt("  %{d} = load {s}, ptr %{d}\n", .{ dst_ssa, type_str, ptr_ssa });
        },

        .store_ptr => |op| {
            const ptr_ssa = ssa_map.get(op.ptr);
            const value_ssa = ssa_map.get(op.value);
            const type_str = widthToLLVMType(op.width);
            try emitter.appendFmt("  store {s} %{d}, ptr %{d}\n", .{ type_str, value_ssa, ptr_ssa });
        },

        .addr_of_field => |op| {
            const base_ssa = ssa_map.get(op.base);
            const dst_ssa = ssa_map.allocFor(op.dst);
            const struct_type = types.struct_types.items[op.struct_idx];
            try emitter.appendFmt("  %{d} = getelementptr inbounds %{s}, ptr %{d}, i32 0, i32 {d}\n", .{
                dst_ssa, struct_type.name, base_ssa, op.field_idx,
            });
        },

        .ptr_offset => |op| {
            const base_ssa = ssa_map.get(op.base);
            const count_ssa = ssa_map.get(op.count);
            if (op.stride == 1) {
                if (op.is_sub) {
                    const neg_ssa = ssa_map.next_ssa;
                    ssa_map.next_ssa += 1;
                    try emitter.appendFmt("  %{d} = sub i64 0, %{d}\n", .{ neg_ssa, count_ssa });
                    const dst_ssa = ssa_map.allocFor(op.dst);
                    try emitter.appendFmt("  %{d} = getelementptr i8, ptr %{d}, i64 %{d}\n", .{ dst_ssa, base_ssa, neg_ssa });
                } else {
                    const dst_ssa = ssa_map.allocFor(op.dst);
                    try emitter.appendFmt("  %{d} = getelementptr i8, ptr %{d}, i64 %{d}\n", .{ dst_ssa, base_ssa, count_ssa });
                }
            } else {
                // sign-extend count to i64, multiply by stride, then GEP
                const ext_ssa = ssa_map.next_ssa;
                ssa_map.next_ssa += 1;
                try emitter.appendFmt("  %{d} = sext i32 %{d} to i64\n", .{ ext_ssa, count_ssa });
                const scaled_ssa = ssa_map.next_ssa;
                ssa_map.next_ssa += 1;
                try emitter.appendFmt("  %{d} = mul i64 %{d}, {d}\n", .{ scaled_ssa, ext_ssa, op.stride });
                if (op.is_sub) {
                    const neg_ssa = ssa_map.next_ssa;
                    ssa_map.next_ssa += 1;
                    try emitter.appendFmt("  %{d} = sub i64 0, %{d}\n", .{ neg_ssa, scaled_ssa });
                    const dst_ssa = ssa_map.allocFor(op.dst);
                    try emitter.appendFmt("  %{d} = getelementptr i8, ptr %{d}, i64 %{d}\n", .{ dst_ssa, base_ssa, neg_ssa });
                } else {
                    const dst_ssa = ssa_map.allocFor(op.dst);
                    try emitter.appendFmt("  %{d} = getelementptr i8, ptr %{d}, i64 %{d}\n", .{ dst_ssa, base_ssa, scaled_ssa });
                }
            }
        },
    }
}

fn ccAttr(cc: CallingConvention) []const u8 {
    return switch (cc) {
        .c => "",
        .honey => "fastcc ",
        else => "",
    };
}

fn widthToLLVMType(width: Width) []const u8 {
    return switch (width) {
        .w8 => "i8",
        .w16 => "i16",
        .w32 => "i32",
        .w64 => "i64",
        .ptr => "ptr",
        .wf16 => "half",
        .wf32 => "float",
        .wf64 => "double",
    };
}

/// Map a TypeId to an LLVM type string (for struct field types in type definitions).
fn typeIdToLLVMType(type_id: TypeId) []const u8 {
    return switch (type_id) {
        .primitive => |p| switch (p) {
            .void => "void",
            .bool => "i1",
            .u8, .i8 => "i8",
            .u16, .i16 => "i16",
            .f16 => "half",
            .u32, .i32 => "i32",
            .f32 => "float",
            .u64, .i64 => "i64",
            .f64 => "double",
        },
        .struct_type => "ptr", // nested struct fields are pointers
        .pointer => "ptr",
        .unresolved => "i32",
        .function => "ptr",
    };
}

fn isFloatType(type_id: TypeId) bool {
    if (type_id != .primitive) return false;
    return switch (type_id.primitive) {
        .f16, .f32, .f64 => true,
        else => false,
    };
}

fn binOpToLLVM(op: BinOp) []const u8 {
    return switch (op) {
        .add => "add",
        .sub => "sub",
        .mul => "mul",
        .div_s => "sdiv",
        .div_u => "udiv",
        .mod_s => "srem",
        .mod_u => "urem",
        .bit_and => "and",
        .bit_or => "or",
        .bit_xor => "xor",
        .shl => "shl",
        .shr_s => "ashr",
        .shr_u => "lshr",
    };
}

fn cmpOpToLLVM(op: CmpOp) []const u8 {
    return switch (op) {
        .eq => "eq",
        .ne => "ne",
        .lt_s => "slt",
        .lt_u => "ult",
        .le_s => "sle",
        .le_u => "ule",
        .gt_s => "sgt",
        .gt_u => "ugt",
        .ge_s => "sge",
        .ge_u => "uge",
    };
}

fn floatBinOpToLLVM(op: BinOp) []const u8 {
    return switch (op) {
        .add => "fadd",
        .sub => "fsub",
        .mul => "fmul",
        .div_s, .div_u => "fdiv",
        .mod_s, .mod_u => "frem",
        else => "fadd", // fallback for bitwise ops (shouldn't occur on floats)
    };
}

fn floatCmpOpToLLVM(op: CmpOp) []const u8 {
    return switch (op) {
        .eq => "oeq",
        .ne => "une",
        .lt_s, .lt_u => "olt",
        .le_s, .le_u => "ole",
        .gt_s, .gt_u => "ogt",
        .ge_s, .ge_u => "oge",
    };
}

/// Map virtual registers to LLVM SSA names.
const SsaMap = struct {
    map: [256]u16 = [_]u16{0} ** 256,
    next_ssa: u16 = 0,

    fn allocFor(self: *SsaMap, vreg: VReg) u16 {
        const ssa = self.next_ssa;
        self.next_ssa += 1;
        if (vreg < 256) {
            self.map[vreg] = ssa;
        }
        return ssa;
    }

    fn get(self: *const SsaMap, vreg: VReg) u16 {
        if (vreg < 256) {
            return self.map[vreg];
        }
        return 0;
    }
};

/// Map fp-relative offsets to alloca identifiers.
/// Tracks which allocas have been emitted to avoid duplicates.
const AllocaMap = struct {
    offsets: [64]i16 = [_]i16{0} ** 64,
    emitted: [64]bool = [_]bool{false} ** 64,
    count: u16 = 0,

    fn getOrCreate(self: *AllocaMap, offset: i16) u16 {
        // check if offset already mapped
        for (self.offsets[0..self.count], 0..) |off, i| {
            if (off == offset) return @intCast(i);
        }
        // new offset
        const id = self.count;
        self.offsets[id] = offset;
        self.count += 1;
        return id;
    }

    fn isEmitted(self: *const AllocaMap, offset: i16) bool {
        for (self.offsets[0..self.count], 0..) |off, i| {
            if (off == offset) return self.emitted[i];
        }
        return false;
    }

    fn markEmitted(self: *AllocaMap, offset: i16) void {
        for (self.offsets[0..self.count], 0..) |off, i| {
            if (off == offset) {
                self.emitted[i] = true;
                return;
            }
        }
    }
};

/// LLVM IR text emitter.
const Emitter = struct {
    allocator: mem.Allocator,
    buffer: std.ArrayList(u8),
    target: Target,

    fn init(allocator: mem.Allocator, target: Target) !Emitter {
        return .{
            .allocator = allocator,
            .buffer = try std.ArrayList(u8).initCapacity(allocator, 4096),
            .target = target,
        };
    }

    fn deinit(self: *Emitter) void {
        self.buffer.deinit(self.allocator);
    }

    fn getOutput(self: *const Emitter) []const u8 {
        return self.buffer.items;
    }

    fn raw(self: *Emitter, text: []const u8) !void {
        try self.buffer.appendSlice(self.allocator, text);
        try self.buffer.append(self.allocator, '\n');
    }

    fn comment(self: *Emitter, msg: []const u8) !void {
        try self.buffer.appendSlice(self.allocator, "; ");
        try self.buffer.appendSlice(self.allocator, msg);
        try self.buffer.append(self.allocator, '\n');
    }

    fn newline(self: *Emitter) !void {
        try self.buffer.append(self.allocator, '\n');
    }

    fn appendSlice(self: *Emitter, text: []const u8) !void {
        try self.buffer.appendSlice(self.allocator, text);
    }

    fn appendFmt(self: *Emitter, comptime fmt: []const u8, args: anytype) !void {
        var buf: [512]u8 = undefined;
        const text = std.fmt.bufPrint(&buf, fmt, args) catch return error.OutOfMemory;
        try self.buffer.appendSlice(self.allocator, text);
    }
};
